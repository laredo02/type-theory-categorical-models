\documentclass[12pt]{book}

\input{packages.tex}

\begin{document}

\chapter{Introduction}

\orange{The flow of the document, what will be covered (UTLC, STLC, DTLC, Curry-Howard, LCCCs...). The aim of the document. Things will be formal but for key constructions that are deemed to be of practical use, a simple implementation will be given, usually in haskell, lean or similar. }

\chapter{\lCalc}

\magenta{Add some introduction. Computation and meaning, extensional vs intensional, operational vs denotational. historical note}

\section{\centering Untyped \lCalc}
In order to get acquainted with the \lcalc, let us develop a simple example to familiarize ourselves before we begin with a more formal approach to this discipline. Consider the function $f(x) = x + 1$, the most straightforward way to express this using \lcalc \ would be $(\la x . x + 1 )$, where the lambda denotes that $x$ is being captured and used as a parameter to perform some computation \footnote{this is an e.g., $(\la x . x + 1 )$ is not a valid lambda term, see Definition \ref{def:lambda-terms-2}.}. Evaluating $f(2)$ using this newly created lambda term would look like this: $(\la x . x + 1)(2) \curly (2 + 1) \curly 3$. This process of reducing a $\la$-expression is referred to as \bred, it will be covered formally later in the chapter.
\begin{definition} The set of lambda terms \( \La \) is defined inductively as follows:
  \label{def:lambda-terms-1}
  \begin{itemize}
  \item (Variable) If \( x \in \Vset \), then \( x \in \La \).  
  \item (Abstraction) If \( x \in \Vset \) and \( M \in \La \), then \( (\la x. M) \in \La \).
  \item (Application) If \( M, N \in \La \), then \((M N) \in \La \).
  \end{itemize}
  Where $\Vset = \{x, y, z, ... \}$ represents a countably infinite set of variable names.
\end{definition}
The key takeaway of this definition is that abstraction and application together, encapsulate the meaning of function in a way that when combined with \bred \ \ref{} allows us to perform computation.

Since we are dealing with a formal language, it is in our benefit to introduce a few other objects with the aim of defining a grammar to generate the set $\La$:
\begin{itemize}
\item An alphabet \( \Sigma = \{ \la, ., (, ), \ldots \} \), is a finite set of symbols
\item A string is a finite sequence of elements from \( \Sigma \), the empty string is denoted by \( \varepsilon \)
\item \( \Sigma^* \) denotes the set of all finite strings over \( \Sigma \), \( \varepsilon \in \Sigma^* \)
\item A language \( L \) over an alphabet \( \Sigma \) is a subset of \( \Sigma^* \)
\end{itemize}
Our aim now, to generate the set $\La$,  to do this, we will make use of a grammar. When dealing with grammars that define programming languages i.e. context-free grammars, Backus-Naur Form is the way to go:
\begin{itemize}
\item Nonterminals are enclosed in angle brackets (e.g. \texttt{<expr>})
\item Terminals are written literally (e.g. \texttt{"$\lambda$"}, \texttt{"."}, $x$)
\item Productions define how nonterminals expand, written as \texttt{::=}
\item The vertical bar \texttt{|} denotes available expansions
\end{itemize}
Thus, to define the language for natural numbers in decimal notation:
\begin{align*}
  \texttt{<digit>} &\;\texttt{::=}\; \texttt{"0"} \;|\; \texttt{"1"} \;|\; \texttt{"2"} \;|\; \texttt{"3"} \;|\; \texttt{"4"} \;|\; \texttt{"5"} \;|\; \texttt{"6"} \;|\; \texttt{"7"} \;|\; \texttt{"8"} \;|\; \texttt{"9"} \\
  \texttt{<number>} &\;\texttt{::=}\; \texttt{<digit>} \;|\; \texttt{<digit>} \ \texttt{<number>}
\end{align*}
\begin{definition} Taking advantage of BNF notation, an alternative definition for $\La$ (\ref{def:lambda-terms-1}):
  \begin{align*}
    \texttt{<term>} &\;\texttt{::=}\; \texttt{<variable>} \\
                    &\;|\; \texttt{"$\la$"}\ \texttt{<variable>}\ \texttt{"."}\ \texttt{<term>} \\
                    &\;|\; \texttt{"("}\ \texttt{<term>}\ \texttt{<term>}\ \texttt{")"} \\
    \texttt{<variable>} &\;\texttt{::}\in V
  \end{align*}
  \label{def:lambda-terms-2}
  where \( \Sigma = \{ \la, ., (, )\} \cup \Vset \) and \( \La \subset \Sigma^* \). Through use of algebraic types \footnote{Algebraic Data Types are inductively defined types built from sums (either this or that) of products (this and that). They let you define structured data with multiple forms and support safe, exhaustive pattern matching. }, this grammar can be implemented in Haskell:
  \begin{lstlisting}[style=haskellstyle,caption={Grammar implementation of the \lcalc \ language using Haskell's algebraic types}]
data LambdaTerm = Var String
                | App LambdaTerm LambdaTerm
                | Abs String LambdaTerm
{- variable names are implemented using strings -}
  \end{lstlisting}
\end{definition}
\begin{remark}
  From the definition above we extract that \( \lambda x . x + 1 \notin \La \), given this circumstance, the need to find an accurate representation for numbers within this definition arises. See Definition \ref{def:church-naturals}
\end{remark}
\begin{example} \label{ex:lambda-terms} Some examples of valid $\la$ terms generated using the grammar in \ref{def:lambda-terms-2}:
  \( y \),
  \( (\la x. (x x)) \),
  \( (\la x. (\la y. x)) \),
  \( (((\la x. (x y)) (\la y. y)) z) \).
  The haskell counterpart for the second term is:
  \begin{lstlisting}[style=haskellstyle,caption={Haskell interpretation of the second term}]
Abs "x" (App (Var "x") (Var "x"))
  \end{lstlisting}
\end{example}
As a convention to avoid notational cluttering, the outermost parenthesis can be omitted e.g. $ ( \la x.x ) $ can be read as $ \la x.x $. Also, application is left-associative  and binds tighter than abstraction, so $M N P$ is parsed as $(M N) P$ and $\la x . M N$ means $\la x . (M N)$, not $(\la x . M) N$. Likewise, abstraction is right-associative e.g. $\la x . \la y . M$ is $\la x . (\la y . M)$ and binds more weakly than application. All these are just to keep notation straight-forward, the formal definition does not leave precedence under-specified thanks to parenthesis.
\subsection{\centering Equivalence of terms}
Having defined the language of the \lcalc, we move on to the mechanics of computation. To this end, several equivalence relations among terms will be defined. Let us begin by introducing the set that contains all variables that are not bound to the term via an abstraction.
\begin{definition} Given $T \in \La $, $\functionfont{FV} : \La \to \mathcal{P}(\Vset) $ outputs the set of free variables for $T$:
  \begin{align*}
    & \FV x = {x}\\
    & \FV {MN} = \FV M \cup \FV N \\
    & \FV {\lambda x . M} = \FV M \setminus \{x\}
  \end{align*}
  Where $ x \in \Vset $ and $ M, N \in \La $, and $\mathcal{P}$ denotes the power set.
\end{definition}
\begin{example}
  Compute the free variables of $\lambda x . \lambda y . y x z$:
  
  The term well-formed, thus belongs to $\La$, so we proceed:
  \begin{align*}
    \FV {\lambda x . \lambda y . y x z} &= \FV {\lambda y . yxz} \setminus \{x\} \\
                                        &= \FV {yxz} \setminus \{x, y\} \\
                                        &= \{x, y, z\} \setminus \{x, y\} \\
                                        &= \{z\}
  \end{align*}
  Of course, $z$ is the only free variable in the expression as it is the only variable that is not captured by some $\la$-abstraction.
\end{example}
\begin{definition}
  A term $M \in \La$ is closed if and only if $\FV M = \emptyset$, closed lambda terms are often referred to as combinators. $\Lambda^0$ is the set of all closed lambda terms.
\end{definition}
Since every lambda term is made up of other smaller lambda terms, it is only natural to define the set that contains all subterms of a given term:
\begin{definition} Given $T \in \La$, $\functionfont{Sub} : \La \to \mathcal{P}(\Vset)$ maps terms to the set of it's subterms.
  \begin{align*}
    &\Sub x = \{x\} \\
    &\Sub {MN} = \Sub M  \cup \Sub N \cup \{MN\} \\
    &\Sub {\la x . M} = \Sub M  \cup \{\la x. M\}
  \end{align*}
  Where $x \in \Vset$ and $M, N \in \La $.
\end{definition}
\begin{remark}
  Let \( \preceq \) be the subterm relation on \lterms, defined by
  \[
    M \preceq N \iff M \in \Sub{ N }
  \]
  \( \preceq \) is a partial order relation. This statement is follows intuitively from the definition, it can be proven using induction on the derivation tree.
\end{remark}
\begin{definition} A term $ S \in \Sub M, \ M \in \Lambda$ is said to be proper if $S \neq M$. $\Sub{M} \setminus \{M\}$ would be the set of proper subterms.
\end{definition}
\begin{definition} Let \( M = \lambda x. N \) be a \lterm:
  \begin{itemize}
  \item The variable \( x \) is the binding variable of the abstraction \( \lambda x. N \).
  \item An occurrence of a variable \( x \) in \( M \) is bound if \( x \in \Sub { \lambda x. N } \).
  \end{itemize}
\end{definition}

\begin{definition}Capture-Avoiding Substitution Rules
  Let \( M, N \in \La \) and \( x, y, z \in \Vset \). The substitution \( M[x := N] \) is defined inductively as:
  \[
    \begin{aligned}
      x[x := N]                       & = N \\
      y[x := N]                       & = y && y \neq x \\
      (M_1\, M_2)[x := N]             & = (M_1[x := N])\,(M_2[x := N]) \\
      (\lambda x. M)[x := N]          & = \lambda x. M \\
      (\lambda y. M)[x := N]          & = \lambda y. (M[x := N]) && y \neq x, y \notin \FV { N } \\
      (\lambda y. M)[x := N]          & = \lambda z. (M[y := z][x := N]) && y \neq x, y \in \FV { N }
    \end{aligned}
  \]
  where \( z \notin \FV { M } \cup \FV { N } \).
\end{definition}

\magenta{Beta reduction}

\newpage
Having covered \bred, we now explore a key aspect of the \lcalc, in the jargon referred to as first-class citizenship, or more formally high-order. When we use high-order to refer to a $\la$-term, we refer to the fact that both functions and arguments are treated indistiguishably, the example below sheds some light on the matter:
\begin{align*}
  \overbrace { (\lambda f . \lambda y . f f y) }^{A} \overbrace{ (\lambda x . x + 1) }^{B} \overbrace{(2)}^{C}
  &\curly (\lambda y .(\lambda x . x + 1) (\lambda x . x + 1)y)(2) \\
  &\curly (\lambda x . x + 1)(\lambda x . x + 1)(2) \\
  &\curly^* (\lambda x . x + 1) (3) \\
  &\curly^* (4)
\end{align*}

Taking a closer look, $A$, applies $f$ twice to $x$, as a consequence, $B$ is being applied twice to $C$. And so, very easily, we have implemented the $ x + 2 $ function via a sequential application of $x + 1$ to $C$. One can intuitively apreciate the computational expresivenes this brings with it, and how the sintactic-semantic homogeneity sets the \lcalc \ apart from the classical set-theoretic approach to functions.

\magenta{normalization + church rosser i.e. confluence}

\subsection{\centering Some Important Constructs}

Within the \lcalc \ there exist a number of conventional constructions that represent key ideas in programming (numbers, booleans, branches and lists among others) In the following we define a few of the most important ones.

We begin defining $ \mathbb{N} $ for no particular reason \orange{other than the natural numbers are the foundation of most of mathematics}. The notion of natural numbers in the \lcalc \ follows from the Peano axioms:
\begin{itemize}
\item (Zero) \( 0 \in \NAT \)
\item (Successor) \( \forall x \in \NAT, s(x) \in \NAT \)
\item (Initial) \( \forall x \in \NAT, s(x) \neq 0 \) \label{def:peano-nat-initial}
\item (Injectivity) \( \forall x, y \in \NAT, s(x) = s(y) \Rightarrow x = y \)
\item (Induction) \( P(0) \land \forall ( P(x) \Rightarrow P(s(x))) \Rightarrow \forall x,  P (x) \)
\end{itemize}
\magenta{Maybe include here a graph to make the intuition behind the axioms explicit}

Say for instance we mean to represent $ 3 $ using Peano notation, we would come up with $ s(s(s(0))) $. To add two numbers one can just use the set of rules:
\[
  \begin{cases}
    n + s(m) = s(n + m) \\
    n + 0 = n
  \end{cases}
\]
A recursive rule that performs the addition, and a base case to stop the recursion for n + 0, since there is no such number that has $ 0 $ as succesor \ref{def:peano-nat-initial}.
\begin{definition} Representation of the set of all naturals, usually referred to as Church numerals:
  \label{def:church-naturals}
  \begin{align*}
    \texttt{0} &\equiv \la f.\la x. x \\
    \texttt{SUCC} &\equiv \la n. \la f. \la x . f ( n f x )
  \end{align*}

\end{definition}
\begin{remark}
  The church numerals have been defined similarly to the peano axioms, that is, by bringing into existance an initial element and using the succesor function to define the rest of them. Let us apply \texttt{SUCC} a few times to illustrate:
  \begin{align*}
    \texttt{0} &\equiv \la f.\la x. x \\
    \texttt{1} &\equiv \la f.\la x. f x \\
    \texttt{2} &\equiv \la f.\la x. f f x \\
    \texttt{3} &\equiv \la f.\la x. f f f x \\
    \texttt{n} &\equiv \la f.\la x. f ^ n x
  \end{align*}
  where $ n $ denotes the number of times we append $ f $.
\end{remark}
Now that we have a construction for the naturals, we can define some arithmetic operations:
\begin{align*}
  \texttt{ADD} &\equiv \la m.\la n. \la f. \la x. m f ( n f x) \\
  \texttt{MUL} &\equiv \la f.\la x. \la f. \la x. m (n f) x \\
  \texttt{ISZERO} &\equiv \lambda n. n\,(\lambda x.\texttt{FALSE})\,\texttt{TRUE}
\end{align*}
This are left as a sidequest since they will not be used in the rest of the text.

The next construction in line are the truth values of boolean logic, ``\textit{true}'' and ``\textit{false}'' for short.
\begin{definition} Boolean truth values:
  \begin{align*}
    \texttt{TRUE} &\equiv \lambda t.\lambda f. t \\
    \texttt{FALSE} &\equiv \lambda t.\lambda f. f
  \end{align*}
\end{definition}
\begin{remark}
  \label{rem:true-false}
  Note how $\TRUE \ M \ N \curly M $ and $ \FALSE \ M \ N \curly N $
\end{remark}
\begin{definition} Conditional, in other words \textit{``if statement''}.
  \begin{align*}
    \texttt{IF} &\equiv \lambda b.\lambda t.\lambda e. b\,t\,e
  \end{align*}
\end{definition}
The reality of the \IF \ is that it is just a combinator that happens to behave as a branching operator whenever we pass a church encoded boolean as a first argument.
\begin{example} On the correct behabiour of $\IF$ i.e. check that it implements branching. $ M, N \in \La $ and $ \IF, \TRUE, \FALSE$ are as usual:
  \[
    \begin{aligned}
      & \IF \ \TRUE \ M \ N \\
      \equiv \ & (\la b.\la t.\la e.\, b\, t\, e) \ \TRUE \ M \ N  \\
      \curly \ & (\la t.\la e.\, \TRUE\ t\, e) \ M \ N  \\
      \curly \ & (\la e.\, \TRUE\ M\, e) \ N  \\
      \curly \ & \TRUE\ M\, N \curly^* M 
    \end{aligned}
    \quad
    \begin{aligned}
      & \IF \ \FALSE \ M \ N \\
      \curly^* \ & \FALSE\ M\, N \curly N
    \end{aligned}
  \]
  So the \IF \ just combines $b, t, e$ in such a way that whenever b is a church encoded boolean either $t$ or $e$ is dropped depending on the truth value of $b$. See Remark \ref{rem:true-false}.
\end{example}
\begin{remark}
  Using the \IF \ we can implement an universal set of logic gates:
  \begin{align*}
    \NOT &\equiv \IF \, b \, \FALSE \, \TRUE \\
    \AND &\equiv \IF \, a \, (\IF \, b \, \TRUE \, \FALSE) \, \FALSE
  \end{align*}
  This allows us to simulate a nand gate, known to be universal \orange{\ref{} universality, conjunctive normal form}. Thus, the lambda calculus is at least equivalent to propositional logic \orange{\ref{} Something on turing completeness}.
\end{remark}
On the same track, another must-have for programmers is lists. Sice they are a bit more involved, we require tuples to define them. Note that the \IF \ is a tuple that contains two elements, we query the first element using a \TRUE \ i.e. the \textit{``then''} branch, and the sencond using a \FALSE \ i.e. the \textit{``else''} branch. We will be using this alternative definition for convenience:
\begin{definition} \( \PAIR \equiv \la x.\la y.\la f. f\,x\,y \)
\end{definition}
\begin{remark}
  This is more convenient since $ \PAIR \, M \, N \curly^* \la f . f \, M \, N  $, which allows us to query the first element using $ (\la f . f \, M \, N) \, \TRUE $ and the second by $ (\la f . f \, M \, N) \, \FALSE $, this motivates the definition below:
\end{remark}
\begin{definition}
\begin{align*}
  \FST &\equiv \la p. p\,(\la x.\la y. x) \\
  \SND &\equiv \la p. p\,(\la x.\la y. y)
\end{align*}
\end{definition}
\begin{proposition} A key property of $ \PAIR $'s is:
  \[\PAIR \, A \, B \equiv_\beta \PAIR \, (\FST \, A \, B) \, (\SND \, A \, B) \]
\end{proposition}
Using pairs, we now can define linear lists, we can achieve this using either left linear trees or right linear trees:
\begin{center}
  \[
    \begin{aligned}
      \boxed{
      \begin{forest}
        [\rotatebox{60}{\texttt{\ldots}}
        [\PAIR
        [\PAIR
        [\NIL]
        [\texttt{ELEM}]
        ]
        [\texttt{ELEM}]
        ]
        [\texttt{ELEM}]
        ]
      \end{forest}
      }
    \end{aligned}
    \quad
    \begin{aligned}
      \boxed{
      \begin{forest}
        [\rotatebox{-60}{\texttt{\ldots}}
        [\texttt{ELEM}]
        [\PAIR
        [\texttt{ELEM}]
        [\PAIR
        [\texttt{ELEM}]
        [\NIL]
        ]]]
      \end{forest}
      }
    \end{aligned}
  \]
\end{center}
\begin{definition} We define \NIL \ in the same way we defined \texttt{0} and \FALSE \ before: $ \NIL \equiv \la f.\la z. z $; \NIL \ represents the terminating element of the inductive definition for lists. To build lists, we cons lists together using:
  \[ \texttt{CONS} \equiv \la h.\la t.\la f.\la z. f\,h\,(t\,f\,z) \]
that binds a new element $h$ to to an pre-existing list or to \NIL.
\end{definition}
\begin{note}
  This notion of inductively defined lists is lays the foundations of the \textbf{LISP} family of programming languages, hence the name (LISt Processing).
\end{note}
\begin{definition} Relevant list operators:
\begin{align*}
  \texttt{ISNIL} &\equiv \la l. l\,(\la h.\la t. \FALSE)\,\TRUE \\
  \texttt{HEAD} &\equiv \la l. l\,(\la h.\la t. h)\,\text{undef}
\end{align*}  
\end{definition}














\newpage
\centering{\blue{left blank}}



\begin{align*}
  \texttt{CONS} &\equiv \la h.\la t.\la f.\la z. f\,h\,(t\,f\,z) \\
  \texttt{IS\_NIL} &\equiv \la l. l\,(\la h.\la t. \texttt{FALSE})\,\texttt{TRUE} \\
  \texttt{HEAD} &\equiv \la l. l\,(\la h.\la t. h)\,\text{undef} \\
  \texttt{TAIL} &\equiv \la l.\, \texttt{FIRST}\,(l\,(\la p.\la h.\, \texttt{PAIR}\,(\texttt{SECOND}\,p)\,(\texttt{CONS}\,h\,(\texttt{SECOND}\,p)))\,(\texttt{PAIR}\,\texttt{NIL}\,\texttt{NIL}))
\end{align*}




\newpage

\textbf{Recursion:}
\begin{align*}
  \texttt{Y} &\equiv \lambda f.(\lambda x. f\,(x\,x))\,(\lambda x. f\,(x\,x))
\end{align*}
\subsection{\centering Fixed Point Combinators and Recursion}
Y combinator.
\[
  Y \triangleq \lambda f.\, (\lambda x.\, f\, (x\, x))\, (\lambda x.\, f\, (x\, x))
\]
Turing combinator
\[
  \Theta \triangleq 
  (\lambda x\, f.\, f\, (x\, x\, f))\, (\lambda x\, f.\, f\, (x\, x\, f))
\]
Z combinator
\[
  Z \triangleq \lambda f.\, 
  (\lambda x.\, f\, (\lambda v.\, x\, x\, v))\, 
  (\lambda x.\, f\, (\lambda v.\, x\, x\, v))
\]
\magenta{Turing completeness of the \lcalc} 
\section{\centering Simply Typed \lCalc}
\magenta{rewrite this pls $==>$}

The Untyped Lambda Calculus in computationally equivalent to a  Turing machine. However, with great computational power comes limited decidability of properties, leading to non-termination, or expressions such as $x(\lambda y . y)$, whose meaning is unclear.

A classic example of non-termination is the $Y$ combinator, however, the Simply Typed Lambda Calculus does not allow such expressions, as its type system is unable to assign a valid type to them.

\magenta{if there is a proof of turing completeness, add how if we remove combinators then we remove turing completeness i.e. finite tape $\neq$ turing complete}

To understand why, consider the role of function types: in the world of functions, a function maps values from a domain to a range. The Simply Typed Lambda Calculus enforces this structure explicitly, ensuring that every function application is well-typed and preventing self-application patterns that would lead to paradoxes or infinite loops.

Having grasped the untyped lambda calculus's Turing completeness and ability to compute all computable functions, we now seek properties related to decidability. To this end, we introduce the simply typed lambda calculus. Although it possesses less computational power than its untyped counterpart, it offers attractive features regarding decidability that will be useful later on.
\chapter{The Curry-Howard Correspondence}
\section*{\centering A Primer on Logic}
\magenta{build up to first order logic}
\end{document}

